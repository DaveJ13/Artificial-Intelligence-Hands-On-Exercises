{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ba53c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tflearn \n",
    "\n",
    "# Download the Titanic dataset\n",
    "from tflearn.datasets import titanic\n",
    "titanic.download_dataset(\"titanic_dataset.csv\")\n",
    "\n",
    "# Download dataset and indicate that the first column represents the labels\n",
    "from tflearn.data_utils import load_csv\n",
    "data, labels = load_csv(\"titanic_dataset.csv\", target_column = 0,\n",
    "                       categorical_labels = True, n_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a47da8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.    ,   1.    ,  29.    ,   0.    ,   0.    , 211.3375],\n",
       "       [  1.    ,   0.    ,   0.9167,   1.    ,   2.    , 151.55  ],\n",
       "       [  1.    ,   1.    ,   2.    ,   1.    ,   2.    , 151.55  ],\n",
       "       ...,\n",
       "       [  3.    ,   0.    ,  26.5   ,   0.    ,   0.    ,   7.225 ],\n",
       "       [  3.    ,   0.    ,  27.    ,   0.    ,   0.    ,   7.225 ],\n",
       "       [  3.    ,   0.    ,  29.    ,   0.    ,   0.    ,   7.875 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fdbc3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  'Allison, Master. Hudson Trevor',\n",
       "  'male',\n",
       "  '0.9167',\n",
       "  '1',\n",
       "  '2',\n",
       "  '113781',\n",
       "  '151.5500'],\n",
       " ['1',\n",
       "  'Allison, Miss. Helen Loraine',\n",
       "  'female',\n",
       "  '2',\n",
       "  '1',\n",
       "  '2',\n",
       "  '113781',\n",
       "  '151.5500'],\n",
       " ['1',\n",
       "  'Allison, Mr. Hudson Joshua Creighton',\n",
       "  'male',\n",
       "  '30',\n",
       "  '1',\n",
       "  '2',\n",
       "  '113781',\n",
       "  '151.5500'],\n",
       " ['1',\n",
       "  'Allison, Mrs. Hudson J C (Bessie Waldo Daniels)',\n",
       "  'female',\n",
       "  '25',\n",
       "  '1',\n",
       "  '2',\n",
       "  '113781',\n",
       "  '151.5500']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8a2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data (define the process): We are not looking for the name of passenger or the ticket number\n",
    "def preprocess(passengers, columns_to_delete):\n",
    "    # Sort by descending ID and delete columns\n",
    "    for column_to_delete in sorted(columns_to_delete, reverse = True):\n",
    "        [passenger.pop(column_to_delete) for passenger in passengers]\n",
    "    for i in range(len(passengers)):\n",
    "        # Converting \"sex\" field to a float value(id is 1 after removing labels column)\n",
    "        passengers[i][1] = 1. if passengers[i][1] == \"female\" else 0\n",
    "    return np.array(passengers, dtype = \"float32\")\n",
    "\n",
    "# Ignore \"name\" and \"ticket\" columns (columns 1 and 6 of data array)\n",
    "to_ignore = [1,6]\n",
    "\n",
    "# Preprocess the data\n",
    "data = preprocess(data, to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a79cc26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Building the neural network\n",
    "net = tflearn.input_data(shape = [None, 6])  # Input layer with 6 features from the data\n",
    "net = tflearn.fully_connected(net, 32)  # two hidden layers with 32 nodes each\n",
    "net = tflearn.fully_connected(net, 32)\n",
    "net = tflearn.fully_connected(net, 2, activation = \"softmax\")  # Output layer with 2 nodes\n",
    "net = tflearn.regression(net)  # Fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26c893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.49442\u001b[0m\u001b[0m | time: 0.296s\n",
      "| Adam | epoch: 010 | loss: 0.49442 - acc: 0.7952 -- iter: 1296/1309\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.47708\u001b[0m\u001b[0m | time: 0.299s\n",
      "| Adam | epoch: 010 | loss: 0.47708 - acc: 0.8094 -- iter: 1309/1309\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = tflearn.DNN(net)\n",
    "# Start the training (apply gradient descent algorithm)\n",
    "model.fit(data, labels, n_epoch = 10, batch_size = 16, show_metric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d97a62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicaprio Surviving Rate: 0.13026267\n",
      "Winslet Surviving Rate: 0.7997492\n"
     ]
    }
   ],
   "source": [
    "# Running the model on made up data\n",
    "dicaprio = [3, \"Jack Dawson\", \"male\", 19, 0, 0, \"N/A\", 5.0000]\n",
    "winslet = [1, \"Rose DeWitt Bukater\" ,\"female\", 17, 1, 2, \"N/A\", 100.0000]\n",
    "# Preprocess the data\n",
    "dicaprio, winslet = preprocess([dicaprio, winslet], to_ignore)\n",
    "# Predict each one's survival chances(class 1 results)\n",
    "pred = model.predict([dicaprio, winslet])\n",
    "print(\"Dicaprio Surviving Rate:\", pred[0][1])\n",
    "print(\"Winslet Surviving Rate:\", pred[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce72ad",
   "metadata": {},
   "source": [
    "### Implementing an RNN with tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cab165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tflearn  # We already have those loaded\n",
    "from __future__ import division, print_function, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e49014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import the data and separate into training and testing sets\n",
    "import tflearn.datasets.mnist as mnist\n",
    "X, Y, testX, testY = mnist.load_data(one_hot = True) #X and Y are the training set and labels for training set\n",
    "# testX and testY are the images in the test set and testY are the labels for the test set\n",
    "X = np.reshape(X, (-1, 28, 28))  # Training set\n",
    "testX = np.reshape(testX, (-1, 28, 28))  # Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f1afe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at a sample of the training data\n",
    "testY[2]  # Digit in this image is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b759381a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[1]  # Digit in this image is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70f3c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]  # Digit in this image is 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9df7d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tflearn\\layers\\recurrent.py:67: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network\n",
    "net = tflearn.input_data(shape = [None, 28, 28])  # 3D layer for an lstm model\n",
    "net = tflearn.lstm(net, 128, return_seq= True)\n",
    "net = tflearn.lstm(net, 128)   # Tow hidden layers with 128 nodes each\n",
    "net = tflearn.fully_connected(net, 10, activation = \"softmax\")\n",
    "net = tflearn.regression(net, optimizer = \"adam\",\n",
    "                        loss = \"categorical_crossentropy\", name = \"output1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "671cd7ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_8/120702378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Build the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit(X, Y, n_epoch = 1, validation_set = 0.1, show_metric = True, \n\u001b[0m\u001b[0;32m      4\u001b[0m          snapshot_step = 100)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# asynchronous feed dict allocation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# TODO: check memory impact for large data and multiple optimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n\u001b[0m\u001b[0;32m    184\u001b[0m                                       self.targets)\n\u001b[0;32m    185\u001b[0m         \u001b[0mfeed_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tflearn\\utils.py\u001b[0m in \u001b[0;36mfeed_dict_builder\u001b[1;34m(X, Y, net_inputs, net_targets)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                 \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# If a dict is provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(X, Y, n_epoch = 1, validation_set = 0.1, show_metric = True, \n",
    "         snapshot_step = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feab624",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d031ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "testY[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
